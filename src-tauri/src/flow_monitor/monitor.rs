//! Flow æ ¸å¿ƒç›‘æ§æœåŠ¡
//!
//! è¯¥æ¨¡å—å®ç° LLM Flow çš„æ ¸å¿ƒç›‘æ§åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
//! - Flow ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆåˆ›å»ºã€æ›´æ–°ã€å®Œæˆã€å¤±è´¥ï¼‰
//! - æµå¼å“åº”å¤„ç†
//! - å®æ—¶äº‹ä»¶å‘é€
//! - æ ‡æ³¨ç®¡ç†

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{broadcast, RwLock};
use uuid::Uuid;

use super::file_store::FlowFileStore;
use super::memory_store::FlowMemoryStore;
use super::models::{
    FlowAnnotations, FlowError, FlowMetadata, FlowState, FlowType, LLMFlow, LLMRequest,
    LLMResponse, TokenUsage,
};
use super::stream_rebuilder::{StreamFormat, StreamRebuilder};

// ============================================================================
// é…ç½®ç»“æ„
// ============================================================================

/// Flow ç›‘æ§é…ç½®
///
/// æ§åˆ¶ Flow Monitor çš„è¡Œä¸ºï¼ŒåŒ…æ‹¬å¯ç”¨/ç¦ç”¨ã€ç¼“å­˜å¤§å°ã€æŒä¹…åŒ–ç­‰ã€‚
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FlowMonitorConfig {
    /// æ˜¯å¦å¯ç”¨ç›‘æ§
    #[serde(default = "default_enabled")]
    pub enabled: bool,
    /// æœ€å¤§å†…å­˜ Flow æ•°é‡
    #[serde(default = "default_max_memory_flows")]
    pub max_memory_flows: usize,
    /// æ˜¯å¦æŒä¹…åŒ–åˆ°æ–‡ä»¶
    #[serde(default = "default_persist_to_file")]
    pub persist_to_file: bool,
    /// ä¿ç•™å¤©æ•°
    #[serde(default = "default_retention_days")]
    pub retention_days: u32,
    /// æ˜¯å¦ä¿å­˜åŸå§‹æµå¼ chunks
    #[serde(default)]
    pub save_stream_chunks: bool,
    /// æœ€å¤§è¯·æ±‚ä½“å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    #[serde(default = "default_max_request_body_size")]
    pub max_request_body_size: usize,
    /// æœ€å¤§å“åº”ä½“å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    #[serde(default = "default_max_response_body_size")]
    pub max_response_body_size: usize,
    /// æ˜¯å¦ä¿å­˜å›¾ç‰‡å†…å®¹
    #[serde(default)]
    pub save_image_content: bool,
    /// ç¼©ç•¥å›¾å¤§å°
    #[serde(default = "default_thumbnail_size")]
    pub thumbnail_size: (u32, u32),
    /// é‡‡æ ·ç‡ï¼ˆ0.0-1.0ï¼Œ1.0 è¡¨ç¤ºå…¨éƒ¨é‡‡æ ·ï¼‰
    #[serde(default = "default_sampling_rate")]
    pub sampling_rate: f32,
    /// æ’é™¤çš„æ¨¡å‹åˆ—è¡¨ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
    #[serde(default)]
    pub excluded_models: Vec<String>,
    /// æ’é™¤çš„è·¯å¾„åˆ—è¡¨ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
    #[serde(default)]
    pub excluded_paths: Vec<String>,
}

fn default_enabled() -> bool {
    true
}

fn default_max_memory_flows() -> usize {
    1000
}

fn default_persist_to_file() -> bool {
    true
}

fn default_retention_days() -> u32 {
    7
}

fn default_max_request_body_size() -> usize {
    10 * 1024 * 1024 // 10MB
}

fn default_max_response_body_size() -> usize {
    10 * 1024 * 1024 // 10MB
}

fn default_thumbnail_size() -> (u32, u32) {
    (128, 128)
}

fn default_sampling_rate() -> f32 {
    1.0
}

impl Default for FlowMonitorConfig {
    fn default() -> Self {
        Self {
            enabled: default_enabled(),
            max_memory_flows: default_max_memory_flows(),
            persist_to_file: default_persist_to_file(),
            retention_days: default_retention_days(),
            save_stream_chunks: false,
            max_request_body_size: default_max_request_body_size(),
            max_response_body_size: default_max_response_body_size(),
            save_image_content: false,
            thumbnail_size: default_thumbnail_size(),
            sampling_rate: default_sampling_rate(),
            excluded_models: Vec::new(),
            excluded_paths: Vec::new(),
        }
    }
}

impl FlowMonitorConfig {
    /// æ£€æŸ¥æ˜¯å¦åº”è¯¥ç›‘æ§è¯¥è¯·æ±‚
    pub fn should_monitor(&self, model: &str, path: &str) -> bool {
        if !self.enabled {
            return false;
        }

        // æ£€æŸ¥é‡‡æ ·ç‡
        if self.sampling_rate < 1.0 {
            let random: f32 = rand::random();
            if random > self.sampling_rate {
                return false;
            }
        }

        // æ£€æŸ¥æ’é™¤çš„æ¨¡å‹
        for pattern in &self.excluded_models {
            if Self::match_pattern(pattern, model) {
                return false;
            }
        }

        // æ£€æŸ¥æ’é™¤çš„è·¯å¾„
        for pattern in &self.excluded_paths {
            if Self::match_pattern(pattern, path) {
                return false;
            }
        }

        true
    }

    /// æ¨¡å¼åŒ¹é…ï¼ˆæ”¯æŒ * é€šé…ç¬¦ï¼‰
    fn match_pattern(pattern: &str, text: &str) -> bool {
        if pattern == "*" {
            return true;
        }

        if pattern.contains('*') {
            let parts: Vec<&str> = pattern.split('*').collect();
            let mut pos = 0;
            let text_lower = text.to_lowercase();

            for (i, part) in parts.iter().enumerate() {
                if part.is_empty() {
                    continue;
                }

                let part_lower = part.to_lowercase();
                if let Some(found_pos) = text_lower[pos..].find(&part_lower) {
                    if i == 0 && found_pos != 0 {
                        return false;
                    }
                    pos += found_pos + part.len();
                } else {
                    return false;
                }
            }

            if !pattern.ends_with('*') && pos != text.len() {
                return false;
            }

            true
        } else {
            text.to_lowercase() == pattern.to_lowercase()
        }
    }
}

// ============================================================================
// äº‹ä»¶ç±»å‹
// ============================================================================

/// Flow æ‘˜è¦ä¿¡æ¯
///
/// ç”¨äºäº‹ä»¶é€šçŸ¥ï¼ŒåŒ…å« Flow çš„å…³é”®ä¿¡æ¯ã€‚
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FlowSummary {
    /// Flow ID
    pub id: String,
    /// æµç±»å‹
    pub flow_type: FlowType,
    /// æ¨¡å‹åç§°
    pub model: String,
    /// æä¾›å•†
    pub provider: String,
    /// çŠ¶æ€
    pub state: FlowState,
    /// åˆ›å»ºæ—¶é—´
    pub created_at: DateTime<Utc>,
    /// è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    pub duration_ms: Option<u64>,
    /// Token ä½¿ç”¨é‡
    pub usage: Option<TokenUsage>,
    /// æ˜¯å¦æœ‰é”™è¯¯
    pub has_error: bool,
    /// æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    pub has_tool_calls: bool,
    /// æ˜¯å¦æœ‰æ€ç»´é“¾
    pub has_thinking: bool,
}

impl From<&LLMFlow> for FlowSummary {
    fn from(flow: &LLMFlow) -> Self {
        Self {
            id: flow.id.clone(),
            flow_type: flow.flow_type.clone(),
            model: flow.request.model.clone(),
            provider: format!("{:?}", flow.metadata.provider),
            state: flow.state.clone(),
            created_at: flow.timestamps.created,
            duration_ms: if flow.timestamps.duration_ms > 0 {
                Some(flow.timestamps.duration_ms)
            } else {
                None
            },
            usage: flow.response.as_ref().map(|r| r.usage.clone()),
            has_error: flow.error.is_some(),
            has_tool_calls: flow
                .response
                .as_ref()
                .map_or(false, |r| !r.tool_calls.is_empty()),
            has_thinking: flow
                .response
                .as_ref()
                .map_or(false, |r| r.thinking.is_some()),
        }
    }
}

/// Flow æ›´æ–°ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FlowUpdate {
    /// æ–°çŠ¶æ€
    pub state: Option<FlowState>,
    /// å†…å®¹å¢é‡
    pub content_delta: Option<String>,
    /// å½“å‰å†…å®¹é•¿åº¦
    pub content_length: Option<usize>,
    /// å½“å‰ chunk æ•°é‡
    pub chunk_count: Option<u32>,
}

/// å®æ—¶ Flow äº‹ä»¶
#[derive(Debug, Clone, Serialize)]
#[serde(tag = "type")]
pub enum FlowEvent {
    /// Flow å¼€å§‹
    FlowStarted { flow: FlowSummary },
    /// Flow æ›´æ–°
    FlowUpdated { id: String, update: FlowUpdate },
    /// Flow å®Œæˆ
    FlowCompleted { id: String, summary: FlowSummary },
    /// Flow å¤±è´¥
    FlowFailed { id: String, error: FlowError },
}

// ============================================================================
// æ´»è·ƒ Flow çŠ¶æ€
// ============================================================================

/// æ´»è·ƒ Flow çŠ¶æ€
///
/// ç”¨äºè·Ÿè¸ªæ­£åœ¨è¿›è¡Œä¸­çš„ Flowï¼ŒåŒ…æ‹¬æµå¼å“åº”é‡å»ºå™¨ã€‚
struct ActiveFlow {
    /// Flow æ•°æ®
    flow: LLMFlow,
    /// æµå¼å“åº”é‡å»ºå™¨ï¼ˆå¦‚æœæ˜¯æµå¼å“åº”ï¼‰
    stream_rebuilder: Option<StreamRebuilder>,
    /// è¯·æ±‚å¼€å§‹æ—¶é—´
    request_start: DateTime<Utc>,
}

// ============================================================================
// æ ¸å¿ƒç›‘æ§æœåŠ¡
// ============================================================================

/// Flow ç›‘æ§æœåŠ¡
///
/// è´Ÿè´£æ•è·å’Œç®¡ç† LLM Flow çš„æ ¸å¿ƒæœåŠ¡ã€‚
pub struct FlowMonitor {
    /// é…ç½®
    config: RwLock<FlowMonitorConfig>,
    /// å†…å­˜å­˜å‚¨
    memory_store: Arc<RwLock<FlowMemoryStore>>,
    /// æ–‡ä»¶å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
    file_store: Option<Arc<FlowFileStore>>,
    /// æ´»è·ƒ Flowï¼ˆæ­£åœ¨è¿›è¡Œä¸­çš„è¯·æ±‚ï¼‰
    active_flows: RwLock<HashMap<String, ActiveFlow>>,
    /// äº‹ä»¶å‘é€å™¨
    event_sender: broadcast::Sender<FlowEvent>,
}

impl FlowMonitor {
    /// åˆ›å»ºæ–°çš„ Flow ç›‘æ§æœåŠ¡
    ///
    /// # å‚æ•°
    /// - `config`: ç›‘æ§é…ç½®
    /// - `file_store`: æ–‡ä»¶å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
    pub fn new(config: FlowMonitorConfig, file_store: Option<Arc<FlowFileStore>>) -> Self {
        let memory_store = Arc::new(RwLock::new(FlowMemoryStore::new(config.max_memory_flows)));
        let (event_sender, _) = broadcast::channel(1000);

        Self {
            config: RwLock::new(config),
            memory_store,
            file_store,
            active_flows: RwLock::new(HashMap::new()),
            event_sender,
        }
    }

    /// è·å–å†…å­˜å­˜å‚¨çš„å¼•ç”¨
    pub fn memory_store(&self) -> Arc<RwLock<FlowMemoryStore>> {
        self.memory_store.clone()
    }

    /// è·å–æ–‡ä»¶å­˜å‚¨çš„å¼•ç”¨
    pub fn file_store(&self) -> Option<Arc<FlowFileStore>> {
        self.file_store.clone()
    }

    /// è·å–å½“å‰é…ç½®
    pub async fn config(&self) -> FlowMonitorConfig {
        self.config.read().await.clone()
    }

    /// æ›´æ–°é…ç½®
    pub async fn update_config(&self, config: FlowMonitorConfig) {
        let mut current = self.config.write().await;

        // å¦‚æœç¼“å­˜å¤§å°æ”¹å˜ï¼Œéœ€è¦è°ƒæ•´å†…å­˜å­˜å‚¨
        if current.max_memory_flows != config.max_memory_flows {
            // åˆ›å»ºæ–°çš„å†…å­˜å­˜å‚¨ï¼ˆæ—§æ•°æ®ä¼šä¸¢å¤±ï¼‰
            // å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è¿ç§»é€»è¾‘
            let mut store = self.memory_store.write().await;
            *store = FlowMemoryStore::new(config.max_memory_flows);
        }

        *current = config;
    }

    /// è®¢é˜…å®æ—¶äº‹ä»¶
    pub fn subscribe(&self) -> broadcast::Receiver<FlowEvent> {
        self.event_sender.subscribe()
    }

    /// å¼€å§‹æ•è·ä¸€ä¸ªæ–°çš„ Flow
    ///
    /// # å‚æ•°
    /// - `request`: LLM è¯·æ±‚
    /// - `metadata`: Flow å…ƒæ•°æ®
    ///
    /// # è¿”å›
    /// - `Some(flow_id)`: æˆåŠŸåˆ›å»º Flowï¼Œè¿”å› Flow ID
    /// - `None`: æ ¹æ®é…ç½®è·³è¿‡ç›‘æ§
    pub async fn start_flow(&self, request: LLMRequest, metadata: FlowMetadata) -> Option<String> {
        let config = self.config.read().await;

        // æ£€æŸ¥æ˜¯å¦åº”è¯¥ç›‘æ§
        if !config.should_monitor(&request.model, &request.path) {
            return None;
        }

        // ç”Ÿæˆå”¯ä¸€ ID
        let flow_id = Uuid::new_v4().to_string();

        // ç¡®å®š Flow ç±»å‹
        let flow_type = Self::determine_flow_type(&request.path);

        // åˆ›å»º Flow
        let flow = LLMFlow::new(flow_id.clone(), flow_type, request.clone(), metadata);

        // åˆ›å»ºæ´»è·ƒ Flow çŠ¶æ€
        let active_flow = ActiveFlow {
            flow: flow.clone(),
            stream_rebuilder: None,
            request_start: Utc::now(),
        };

        // æ·»åŠ åˆ°æ´»è·ƒ Flow
        {
            let mut active = self.active_flows.write().await;
            active.insert(flow_id.clone(), active_flow);
        }

        // å‘é€äº‹ä»¶
        let summary = FlowSummary::from(&flow);
        let _ = self
            .event_sender
            .send(FlowEvent::FlowStarted { flow: summary });

        Some(flow_id)
    }

    /// æ ¹æ®è·¯å¾„ç¡®å®š Flow ç±»å‹
    fn determine_flow_type(path: &str) -> FlowType {
        let path_lower = path.to_lowercase();

        if path_lower.contains("/chat/completions") {
            FlowType::ChatCompletions
        } else if path_lower.contains("/messages") {
            FlowType::AnthropicMessages
        } else if path_lower.contains(":generatecontent") || path_lower.contains("/generate") {
            FlowType::GeminiGenerateContent
        } else if path_lower.contains("/embeddings") {
            FlowType::Embeddings
        } else {
            FlowType::Other(path.to_string())
        }
    }

    /// è®¾ç½® Flow ä¸ºæµå¼æ¨¡å¼
    ///
    /// # å‚æ•°
    /// - `flow_id`: Flow ID
    /// - `format`: æµå¼å“åº”æ ¼å¼
    pub async fn set_streaming(&self, flow_id: &str, format: StreamFormat) {
        let config = self.config.read().await;
        let save_chunks = config.save_stream_chunks;
        drop(config);

        let mut active = self.active_flows.write().await;
        if let Some(active_flow) = active.get_mut(flow_id) {
            active_flow.flow.state = FlowState::Streaming;
            active_flow.stream_rebuilder =
                Some(StreamRebuilder::new(format).with_save_raw_chunks(save_chunks));

            // å‘é€æ›´æ–°äº‹ä»¶
            let _ = self.event_sender.send(FlowEvent::FlowUpdated {
                id: flow_id.to_string(),
                update: FlowUpdate {
                    state: Some(FlowState::Streaming),
                    content_delta: None,
                    content_length: None,
                    chunk_count: None,
                },
            });
        }
    }

    /// å¤„ç†æµå¼ chunk
    ///
    /// # å‚æ•°
    /// - `flow_id`: Flow ID
    /// - `event`: SSE äº‹ä»¶ç±»å‹ï¼ˆå¯é€‰ï¼‰
    /// - `data`: SSE æ•°æ®å†…å®¹
    pub async fn process_chunk(&self, flow_id: &str, event: Option<&str>, data: &str) {
        let mut active = self.active_flows.write().await;
        if let Some(active_flow) = active.get_mut(flow_id) {
            if let Some(ref mut rebuilder) = active_flow.stream_rebuilder {
                // å¤„ç† chunk
                if let Err(e) = rebuilder.process_event(event, data) {
                    tracing::warn!("å¤„ç†æµå¼ chunk å¤±è´¥: {}", e);
                }

                // å‘é€æ›´æ–°äº‹ä»¶ï¼ˆå¯é€‰ï¼Œæ ¹æ®éœ€è¦è°ƒæ•´é¢‘ç‡ï¼‰
                // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œæ¯ä¸ª chunk éƒ½å‘é€äº‹ä»¶
                // å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦èŠ‚æµ
            }
        }
    }

    /// å®Œæˆ Flow
    ///
    /// # å‚æ•°
    /// - `flow_id`: Flow ID
    /// - `response`: LLM å“åº”ï¼ˆå¦‚æœæ˜¯éæµå¼å“åº”ï¼‰
    pub async fn complete_flow(&self, flow_id: &str, response: Option<LLMResponse>) {
        let mut active = self.active_flows.write().await;

        if let Some(mut active_flow) = active.remove(flow_id) {
            let now = Utc::now();

            // å¦‚æœæœ‰æµå¼é‡å»ºå™¨ï¼Œä½¿ç”¨é‡å»ºçš„å“åº”
            let final_response = if let Some(rebuilder) = active_flow.stream_rebuilder.take() {
                Some(rebuilder.finish())
            } else {
                response
            };

            // æ›´æ–° Flow
            active_flow.flow.response = final_response;
            active_flow.flow.state = FlowState::Completed;
            active_flow.flow.timestamps.response_end = Some(now);
            active_flow.flow.timestamps.calculate_duration();
            active_flow.flow.timestamps.calculate_ttfb();

            // ä¿å­˜åˆ°å†…å­˜å­˜å‚¨
            {
                let mut store = self.memory_store.write().await;
                store.add(active_flow.flow.clone());
            }

            // ä¿å­˜åˆ°æ–‡ä»¶å­˜å‚¨
            if let Some(ref file_store) = self.file_store {
                if let Err(e) = file_store.write(&active_flow.flow) {
                    tracing::error!("ä¿å­˜ Flow åˆ°æ–‡ä»¶å¤±è´¥: {}", e);
                }
            }

            // å‘é€å®Œæˆäº‹ä»¶
            let summary = FlowSummary::from(&active_flow.flow);
            let _ = self.event_sender.send(FlowEvent::FlowCompleted {
                id: flow_id.to_string(),
                summary,
            });
        }
    }

    /// æ ‡è®° Flow å¤±è´¥
    ///
    /// # å‚æ•°
    /// - `flow_id`: Flow ID
    /// - `error`: é”™è¯¯ä¿¡æ¯
    pub async fn fail_flow(&self, flow_id: &str, error: FlowError) {
        let mut active = self.active_flows.write().await;

        if let Some(mut active_flow) = active.remove(flow_id) {
            let now = Utc::now();

            // æ›´æ–° Flow
            active_flow.flow.error = Some(error.clone());
            active_flow.flow.state = FlowState::Failed;
            active_flow.flow.timestamps.response_end = Some(now);
            active_flow.flow.timestamps.calculate_duration();

            // ä¿å­˜åˆ°å†…å­˜å­˜å‚¨
            {
                let mut store = self.memory_store.write().await;
                store.add(active_flow.flow.clone());
            }

            // ä¿å­˜åˆ°æ–‡ä»¶å­˜å‚¨
            if let Some(ref file_store) = self.file_store {
                if let Err(e) = file_store.write(&active_flow.flow) {
                    tracing::error!("ä¿å­˜ Flow åˆ°æ–‡ä»¶å¤±è´¥: {}", e);
                }
            }

            // å‘é€å¤±è´¥äº‹ä»¶
            let _ = self.event_sender.send(FlowEvent::FlowFailed {
                id: flow_id.to_string(),
                error,
            });
        }
    }

    /// å–æ¶ˆ Flow
    ///
    /// # å‚æ•°
    /// - `flow_id`: Flow ID
    pub async fn cancel_flow(&self, flow_id: &str) {
        let mut active = self.active_flows.write().await;

        if let Some(mut active_flow) = active.remove(flow_id) {
            let now = Utc::now();

            // æ›´æ–° Flow
            active_flow.flow.state = FlowState::Cancelled;
            active_flow.flow.timestamps.response_end = Some(now);
            active_flow.flow.timestamps.calculate_duration();

            // ä¿å­˜åˆ°å†…å­˜å­˜å‚¨
            {
                let mut store = self.memory_store.write().await;
                store.add(active_flow.flow.clone());
            }

            // ä¿å­˜åˆ°æ–‡ä»¶å­˜å‚¨
            if let Some(ref file_store) = self.file_store {
                if let Err(e) = file_store.write(&active_flow.flow) {
                    tracing::error!("ä¿å­˜ Flow åˆ°æ–‡ä»¶å¤±è´¥: {}", e);
                }
            }
        }
    }

    /// æ›´æ–° Flow æ ‡æ³¨
    ///
    /// # å‚æ•°
    /// - `flow_id`: Flow ID
    /// - `annotations`: æ–°çš„æ ‡æ³¨ä¿¡æ¯
    ///
    /// # è¿”å›
    /// - `true`: æ›´æ–°æˆåŠŸ
    /// - `false`: Flow ä¸å­˜åœ¨
    pub async fn update_annotations(&self, flow_id: &str, annotations: FlowAnnotations) -> bool {
        // å…ˆå°è¯•æ›´æ–°å†…å­˜ä¸­çš„ Flow
        let updated = {
            let store = self.memory_store.read().await;
            store.update(flow_id, |flow| {
                flow.annotations = annotations.clone();
            })
        };

        // å¦‚æœå†…å­˜ä¸­å­˜åœ¨ï¼ŒåŒæ—¶æ›´æ–°æ–‡ä»¶å­˜å‚¨çš„ç´¢å¼•
        if updated {
            if let Some(ref file_store) = self.file_store {
                if let Err(e) = file_store.update_annotations(flow_id, &annotations) {
                    tracing::error!("æ›´æ–°æ–‡ä»¶å­˜å‚¨æ ‡æ³¨å¤±è´¥: {}", e);
                }
            }
        }

        updated
    }

    /// æ”¶è—/å–æ¶ˆæ”¶è— Flow
    pub async fn toggle_starred(&self, flow_id: &str) -> bool {
        let store = self.memory_store.read().await;
        store.update(flow_id, |flow| {
            flow.annotations.starred = !flow.annotations.starred;
        })
    }

    /// æ·»åŠ è¯„è®º
    pub async fn add_comment(&self, flow_id: &str, comment: String) -> bool {
        let store = self.memory_store.read().await;
        store.update(flow_id, |flow| {
            flow.annotations.comment = Some(comment);
        })
    }

    /// æ·»åŠ æ ‡ç­¾
    pub async fn add_tag(&self, flow_id: &str, tag: String) -> bool {
        let store = self.memory_store.read().await;
        store.update(flow_id, |flow| {
            if !flow.annotations.tags.contains(&tag) {
                flow.annotations.tags.push(tag);
            }
        })
    }

    /// ç§»é™¤æ ‡ç­¾
    pub async fn remove_tag(&self, flow_id: &str, tag: &str) -> bool {
        let store = self.memory_store.read().await;
        store.update(flow_id, |flow| {
            flow.annotations.tags.retain(|t| t != tag);
        })
    }

    /// è®¾ç½®æ ‡è®°
    pub async fn set_marker(&self, flow_id: &str, marker: Option<String>) -> bool {
        let store = self.memory_store.read().await;
        store.update(flow_id, |flow| {
            flow.annotations.marker = marker;
        })
    }

    /// è·å–æ´»è·ƒ Flow æ•°é‡
    pub async fn active_flow_count(&self) -> usize {
        self.active_flows.read().await.len()
    }

    /// è·å–å†…å­˜ä¸­çš„ Flow æ•°é‡
    pub async fn memory_flow_count(&self) -> usize {
        self.memory_store.read().await.len()
    }

    /// æ£€æŸ¥ç›‘æ§æ˜¯å¦å¯ç”¨
    pub async fn is_enabled(&self) -> bool {
        self.config.read().await.enabled
    }

    /// å¯ç”¨ç›‘æ§
    pub async fn enable(&self) {
        self.config.write().await.enabled = true;
    }

    /// ç¦ç”¨ç›‘æ§
    pub async fn disable(&self) {
        self.config.write().await.enabled = false;
    }
}

// ============================================================================
// æµ‹è¯•æ¨¡å—
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;
    use crate::flow_monitor::models::{
        FlowMetadata, LLMRequest, Message, MessageContent, MessageRole, RequestParameters,
    };
    use crate::ProviderType;

    /// åˆ›å»ºæµ‹è¯•ç”¨çš„ LLMRequest
    fn create_test_request(model: &str, path: &str) -> LLMRequest {
        LLMRequest {
            method: "POST".to_string(),
            path: path.to_string(),
            headers: HashMap::new(),
            body: serde_json::Value::Null,
            messages: vec![Message {
                role: MessageRole::User,
                content: MessageContent::Text("Hello".to_string()),
                tool_calls: None,
                tool_result: None,
                name: None,
            }],
            system_prompt: None,
            tools: None,
            model: model.to_string(),
            original_model: None,
            parameters: RequestParameters::default(),
            size_bytes: 0,
            timestamp: Utc::now(),
        }
    }

    /// åˆ›å»ºæµ‹è¯•ç”¨çš„ FlowMetadata
    fn create_test_metadata(provider: ProviderType) -> FlowMetadata {
        FlowMetadata {
            provider,
            credential_id: Some("test-cred".to_string()),
            credential_name: Some("Test Credential".to_string()),
            ..Default::default()
        }
    }

    #[tokio::test]
    async fn test_flow_monitor_creation() {
        let config = FlowMonitorConfig::default();
        let monitor = FlowMonitor::new(config, None);

        assert!(monitor.is_enabled().await);
        assert_eq!(monitor.active_flow_count().await, 0);
        assert_eq!(monitor.memory_flow_count().await, 0);
    }

    #[tokio::test]
    async fn test_start_flow() {
        let config = FlowMonitorConfig::default();
        let monitor = FlowMonitor::new(config, None);

        let request = create_test_request("gpt-4", "/v1/chat/completions");
        let metadata = create_test_metadata(ProviderType::OpenAI);

        let flow_id = monitor.start_flow(request, metadata).await;

        assert!(flow_id.is_some());
        assert_eq!(monitor.active_flow_count().await, 1);
    }

    #[tokio::test]
    async fn test_complete_flow() {
        let config = FlowMonitorConfig::default();
        let monitor = FlowMonitor::new(config, None);

        let request = create_test_request("gpt-4", "/v1/chat/completions");
        let metadata = create_test_metadata(ProviderType::OpenAI);

        let flow_id = monitor.start_flow(request, metadata).await.unwrap();

        // å®Œæˆ Flow
        monitor.complete_flow(&flow_id, None).await;

        assert_eq!(monitor.active_flow_count().await, 0);
        assert_eq!(monitor.memory_flow_count().await, 1);
    }

    #[tokio::test]
    async fn test_fail_flow() {
        let config = FlowMonitorConfig::default();
        let monitor = FlowMonitor::new(config, None);

        let request = create_test_request("gpt-4", "/v1/chat/completions");
        let metadata = create_test_metadata(ProviderType::OpenAI);

        let flow_id = monitor.start_flow(request, metadata).await.unwrap();

        // å¤±è´¥ Flow
        let error = FlowError::new(
            crate::flow_monitor::models::FlowErrorType::Network,
            "Connection failed",
        );
        monitor.fail_flow(&flow_id, error).await;

        assert_eq!(monitor.active_flow_count().await, 0);
        assert_eq!(monitor.memory_flow_count().await, 1);
    }

    #[tokio::test]
    async fn test_config_should_monitor() {
        let config = FlowMonitorConfig {
            enabled: true,
            sampling_rate: 1.0,
            excluded_models: vec!["test-*".to_string()],
            excluded_paths: vec!["/health".to_string()],
            ..Default::default()
        };

        // æ­£å¸¸è¯·æ±‚åº”è¯¥è¢«ç›‘æ§
        assert!(config.should_monitor("gpt-4", "/v1/chat/completions"));

        // æ’é™¤çš„æ¨¡å‹ä¸åº”è¯¥è¢«ç›‘æ§
        assert!(!config.should_monitor("test-model", "/v1/chat/completions"));

        // æ’é™¤çš„è·¯å¾„ä¸åº”è¯¥è¢«ç›‘æ§
        assert!(!config.should_monitor("gpt-4", "/health"));
    }

    #[tokio::test]
    async fn test_disabled_monitor() {
        let config = FlowMonitorConfig {
            enabled: false,
            ..Default::default()
        };
        let monitor = FlowMonitor::new(config, None);

        let request = create_test_request("gpt-4", "/v1/chat/completions");
        let metadata = create_test_metadata(ProviderType::OpenAI);

        // ç¦ç”¨æ—¶ä¸åº”è¯¥åˆ›å»º Flow
        let flow_id = monitor.start_flow(request, metadata).await;
        assert!(flow_id.is_none());
    }

    #[tokio::test]
    async fn test_event_subscription() {
        let config = FlowMonitorConfig::default();
        let monitor = FlowMonitor::new(config, None);

        let mut receiver = monitor.subscribe();

        let request = create_test_request("gpt-4", "/v1/chat/completions");
        let metadata = create_test_metadata(ProviderType::OpenAI);

        let flow_id = monitor.start_flow(request, metadata).await.unwrap();

        // åº”è¯¥æ”¶åˆ° FlowStarted äº‹ä»¶
        let event = receiver.try_recv();
        assert!(event.is_ok());
        if let FlowEvent::FlowStarted { flow } = event.unwrap() {
            assert_eq!(flow.id, flow_id);
            assert_eq!(flow.model, "gpt-4");
        } else {
            panic!("Expected FlowStarted event");
        }
    }

    #[tokio::test]
    async fn test_flow_type_detection() {
        assert_eq!(
            FlowMonitor::determine_flow_type("/v1/chat/completions"),
            FlowType::ChatCompletions
        );
        assert_eq!(
            FlowMonitor::determine_flow_type("/v1/messages"),
            FlowType::AnthropicMessages
        );
        assert_eq!(
            FlowMonitor::determine_flow_type("/v1/models/gemini-pro:generatecontent"),
            FlowType::GeminiGenerateContent
        );
        assert_eq!(
            FlowMonitor::determine_flow_type("/v1/embeddings"),
            FlowType::Embeddings
        );
    }

    #[tokio::test]
    async fn test_annotations_update() {
        let config = FlowMonitorConfig::default();
        let monitor = FlowMonitor::new(config, None);

        let request = create_test_request("gpt-4", "/v1/chat/completions");
        let metadata = create_test_metadata(ProviderType::OpenAI);

        let flow_id = monitor.start_flow(request, metadata).await.unwrap();
        monitor.complete_flow(&flow_id, None).await;

        // æµ‹è¯•æ”¶è—
        assert!(monitor.toggle_starred(&flow_id).await);

        // æµ‹è¯•æ·»åŠ è¯„è®º
        assert!(
            monitor
                .add_comment(&flow_id, "Test comment".to_string())
                .await
        );

        // æµ‹è¯•æ·»åŠ æ ‡ç­¾
        assert!(monitor.add_tag(&flow_id, "important".to_string()).await);

        // æµ‹è¯•è®¾ç½®æ ‡è®°
        assert!(monitor.set_marker(&flow_id, Some("â­".to_string())).await);
    }
}

// ============================================================================
// å±æ€§æµ‹è¯•æ¨¡å—
// ============================================================================

#[cfg(test)]
mod property_tests {
    use super::*;
    use crate::flow_monitor::models::{
        FlowErrorType, FlowMetadata, LLMRequest, Message, MessageContent, MessageRole,
        RequestParameters,
    };
    use crate::ProviderType;
    use proptest::prelude::*;
    use tokio::runtime::Runtime;

    // ========================================================================
    // ç”Ÿæˆå™¨
    // ========================================================================

    /// ç”Ÿæˆéšæœºçš„ ProviderType
    fn arb_provider_type() -> impl Strategy<Value = ProviderType> {
        prop_oneof![
            Just(ProviderType::Kiro),
            Just(ProviderType::Gemini),
            Just(ProviderType::Qwen),
            Just(ProviderType::OpenAI),
            Just(ProviderType::Claude),
            Just(ProviderType::Antigravity),
        ]
    }

    /// ç”Ÿæˆéšæœºçš„æ¨¡å‹åç§°
    fn arb_model_name() -> impl Strategy<Value = String> {
        prop_oneof![
            Just("gpt-4".to_string()),
            Just("gpt-4-turbo".to_string()),
            Just("gpt-3.5-turbo".to_string()),
            Just("claude-3-opus".to_string()),
            Just("claude-3-sonnet".to_string()),
            Just("gemini-pro".to_string()),
        ]
    }

    /// ç”Ÿæˆéšæœºçš„è·¯å¾„
    fn arb_path() -> impl Strategy<Value = String> {
        prop_oneof![
            Just("/v1/chat/completions".to_string()),
            Just("/v1/messages".to_string()),
            Just("/v1/embeddings".to_string()),
        ]
    }

    /// ç”Ÿæˆéšæœºçš„ LLMRequest
    fn arb_llm_request() -> impl Strategy<Value = LLMRequest> {
        (arb_model_name(), arb_path()).prop_map(|(model, path)| LLMRequest {
            method: "POST".to_string(),
            path,
            headers: HashMap::new(),
            body: serde_json::Value::Null,
            messages: vec![Message {
                role: MessageRole::User,
                content: MessageContent::Text("Test message".to_string()),
                tool_calls: None,
                tool_result: None,
                name: None,
            }],
            system_prompt: None,
            tools: None,
            model,
            original_model: None,
            parameters: RequestParameters::default(),
            size_bytes: 0,
            timestamp: Utc::now(),
        })
    }

    /// ç”Ÿæˆéšæœºçš„ FlowMetadata
    fn arb_flow_metadata() -> impl Strategy<Value = FlowMetadata> {
        arb_provider_type().prop_map(|provider| FlowMetadata {
            provider,
            credential_id: Some("test-cred".to_string()),
            credential_name: Some("Test Credential".to_string()),
            ..Default::default()
        })
    }

    /// ç”Ÿæˆéšæœºçš„ FlowErrorType
    fn arb_flow_error_type() -> impl Strategy<Value = FlowErrorType> {
        prop_oneof![
            Just(FlowErrorType::Network),
            Just(FlowErrorType::Timeout),
            Just(FlowErrorType::Authentication),
            Just(FlowErrorType::RateLimit),
            Just(FlowErrorType::ServerError),
            Just(FlowErrorType::BadRequest),
        ]
    }

    // ========================================================================
    // å±æ€§æµ‹è¯•
    // ========================================================================

    proptest! {
        #![proptest_config(ProptestConfig::with_cases(20))]

        /// **Feature: llm-flow-monitor, Property 9: äº‹ä»¶å‘é€æ­£ç¡®æ€§**
        /// **Validates: Requirements 6.1, 6.2, 6.3, 6.4**
        ///
        /// *å¯¹äºä»»æ„* Flow ç”Ÿå‘½å‘¨æœŸæ“ä½œï¼ˆå¼€å§‹ã€æ›´æ–°ã€å®Œæˆã€å¤±è´¥ï¼‰ï¼Œ
        /// åº”è¯¥å‘å‡ºå¯¹åº”çš„äº‹ä»¶ï¼Œä¸”äº‹ä»¶å†…å®¹åº”è¯¥æ­£ç¡®åæ˜  Flow çŠ¶æ€ã€‚
        #[test]
        fn prop_event_emission_correctness(
            request in arb_llm_request(),
            metadata in arb_flow_metadata(),
        ) {
            let rt = Runtime::new().unwrap();
            rt.block_on(async {
                let config = FlowMonitorConfig::default();
                let monitor = FlowMonitor::new(config, None);

                let mut receiver = monitor.subscribe();

                // å¼€å§‹ Flow
                let flow_id = monitor.start_flow(request.clone(), metadata.clone()).await;
                prop_assert!(flow_id.is_some(), "Flow åº”è¯¥è¢«åˆ›å»º");
                let flow_id = flow_id.unwrap();

                // éªŒè¯ FlowStarted äº‹ä»¶
                let event = receiver.try_recv();
                prop_assert!(event.is_ok(), "åº”è¯¥æ”¶åˆ° FlowStarted äº‹ä»¶");
                if let FlowEvent::FlowStarted { flow } = event.unwrap() {
                    prop_assert_eq!(flow.id, flow_id.clone(), "äº‹ä»¶ä¸­çš„ Flow ID åº”è¯¥æ­£ç¡®");
                    prop_assert_eq!(flow.model, request.model, "äº‹ä»¶ä¸­çš„æ¨¡å‹åº”è¯¥æ­£ç¡®");
                    prop_assert_eq!(
                        flow.state,
                        FlowState::Pending,
                        "æ–° Flow çŠ¶æ€åº”è¯¥æ˜¯ Pending"
                    );
                } else {
                    prop_assert!(false, "åº”è¯¥æ˜¯ FlowStarted äº‹ä»¶");
                }

                // å®Œæˆ Flow
                monitor.complete_flow(&flow_id, None).await;

                // éªŒè¯ FlowCompleted äº‹ä»¶
                let event = receiver.try_recv();
                prop_assert!(event.is_ok(), "åº”è¯¥æ”¶åˆ° FlowCompleted äº‹ä»¶");
                if let FlowEvent::FlowCompleted { id, summary } = event.unwrap() {
                    prop_assert_eq!(id, flow_id.clone(), "äº‹ä»¶ä¸­çš„ Flow ID åº”è¯¥æ­£ç¡®");
                    prop_assert_eq!(
                        summary.state,
                        FlowState::Completed,
                        "å®ŒæˆåçŠ¶æ€åº”è¯¥æ˜¯ Completed"
                    );
                } else {
                    prop_assert!(false, "åº”è¯¥æ˜¯ FlowCompleted äº‹ä»¶");
                }

                Ok(())
            })?;
        }

        /// **Feature: llm-flow-monitor, Property 9b: å¤±è´¥äº‹ä»¶å‘é€æ­£ç¡®æ€§**
        /// **Validates: Requirements 6.4**
        ///
        /// *å¯¹äºä»»æ„* Flow å¤±è´¥æ“ä½œï¼Œåº”è¯¥å‘å‡º FlowFailed äº‹ä»¶ï¼Œ
        /// ä¸”äº‹ä»¶å†…å®¹åº”è¯¥åŒ…å«æ­£ç¡®çš„é”™è¯¯ä¿¡æ¯ã€‚
        #[test]
        fn prop_failure_event_correctness(
            request in arb_llm_request(),
            metadata in arb_flow_metadata(),
            error_type in arb_flow_error_type(),
        ) {
            let rt = Runtime::new().unwrap();
            rt.block_on(async {
                let config = FlowMonitorConfig::default();
                let monitor = FlowMonitor::new(config, None);

                let mut receiver = monitor.subscribe();

                // å¼€å§‹ Flow
                let flow_id = monitor.start_flow(request, metadata).await.unwrap();

                // æ¶ˆè´¹ FlowStarted äº‹ä»¶
                let _ = receiver.try_recv();

                // å¤±è´¥ Flow
                let error = FlowError::new(error_type.clone(), "Test error message");
                monitor.fail_flow(&flow_id, error.clone()).await;

                // éªŒè¯ FlowFailed äº‹ä»¶
                let event = receiver.try_recv();
                prop_assert!(event.is_ok(), "åº”è¯¥æ”¶åˆ° FlowFailed äº‹ä»¶");
                if let FlowEvent::FlowFailed { id, error: evt_error } = event.unwrap() {
                    prop_assert_eq!(id, flow_id, "äº‹ä»¶ä¸­çš„ Flow ID åº”è¯¥æ­£ç¡®");
                    prop_assert_eq!(
                        evt_error.error_type,
                        error_type,
                        "äº‹ä»¶ä¸­çš„é”™è¯¯ç±»å‹åº”è¯¥æ­£ç¡®"
                    );
                    prop_assert_eq!(
                        evt_error.message,
                        "Test error message",
                        "äº‹ä»¶ä¸­çš„é”™è¯¯æ¶ˆæ¯åº”è¯¥æ­£ç¡®"
                    );
                } else {
                    prop_assert!(false, "åº”è¯¥æ˜¯ FlowFailed äº‹ä»¶");
                }

                Ok(())
            })?;
        }

        /// **Feature: llm-flow-monitor, Property 10: æ ‡æ³¨ Round-Trip**
        /// **Validates: Requirements 7.1, 7.2, 7.3, 7.4**
        ///
        /// *å¯¹äºä»»æ„* Flow å’Œæ ‡æ³¨æ“ä½œï¼ˆæ”¶è—ã€è¯„è®ºã€æ ‡ç­¾ã€æ ‡è®°ï¼‰ï¼Œ
        /// æ›´æ–°åå†è¯»å–ï¼Œæ ‡æ³¨ä¿¡æ¯åº”è¯¥ä¸è®¾ç½®çš„å€¼ä¸€è‡´ã€‚
        #[test]
        fn prop_annotation_roundtrip(
            request in arb_llm_request(),
            metadata in arb_flow_metadata(),
            starred in any::<bool>(),
            comment in prop::option::of("[a-zA-Z0-9 ]{1,50}"),
            marker in prop::option::of(prop_oneof![
                Just("â­".to_string()),
                Just("ğŸ”´".to_string()),
                Just("ğŸŸ¢".to_string()),
            ]),
            tags in prop::collection::vec("[a-z]{3,10}", 0..3),
        ) {
            let rt = Runtime::new().unwrap();
            rt.block_on(async {
                let config = FlowMonitorConfig::default();
                let monitor = FlowMonitor::new(config, None);

                // åˆ›å»ºå¹¶å®Œæˆ Flow
                let flow_id = monitor.start_flow(request, metadata).await.unwrap();
                monitor.complete_flow(&flow_id, None).await;

                // è®¾ç½®æ ‡æ³¨
                let annotations = FlowAnnotations {
                    starred,
                    comment: comment.clone(),
                    marker: marker.clone(),
                    tags: tags.clone(),
                };

                let updated = monitor.update_annotations(&flow_id, annotations.clone()).await;
                prop_assert!(updated, "æ ‡æ³¨æ›´æ–°åº”è¯¥æˆåŠŸ");

                // è¯»å–å¹¶éªŒè¯
                let store = monitor.memory_store.read().await;
                let flow_lock = store.get(&flow_id);
                prop_assert!(flow_lock.is_some(), "Flow åº”è¯¥å­˜åœ¨");

                let binding = flow_lock.unwrap();
                let flow = binding.read().unwrap();
                prop_assert_eq!(flow.annotations.starred, starred, "æ”¶è—çŠ¶æ€åº”è¯¥ä¸€è‡´");
                prop_assert_eq!(flow.annotations.comment.clone(), comment, "è¯„è®ºåº”è¯¥ä¸€è‡´");
                prop_assert_eq!(flow.annotations.marker.clone(), marker, "æ ‡è®°åº”è¯¥ä¸€è‡´");
                prop_assert_eq!(flow.annotations.tags.clone(), tags, "æ ‡ç­¾åº”è¯¥ä¸€è‡´");

                Ok(())
            })?;
        }

        /// **Feature: llm-flow-monitor, Property 12: é…ç½®ç”Ÿæ•ˆå±æ€§**
        /// **Validates: Requirements 11.1, 11.2, 11.7, 11.8**
        ///
        /// *å¯¹äºä»»æ„* ç›‘æ§é…ç½®ï¼ˆå¯ç”¨/ç¦ç”¨ã€ç¼“å­˜å¤§å°ã€é‡‡æ ·ç‡ã€æ’é™¤è§„åˆ™ï¼‰ï¼Œ
        /// Flow_Monitor çš„è¡Œä¸ºåº”è¯¥ç¬¦åˆé…ç½®ã€‚
        #[test]
        fn prop_config_effectiveness(
            enabled in any::<bool>(),
            max_memory_flows in 10usize..100usize,
            excluded_model in prop::option::of("[a-z]{3,10}"),
        ) {
            let rt = Runtime::new().unwrap();
            rt.block_on(async {
                // æ„å»ºé…ç½®
                let excluded_models = excluded_model
                    .clone()
                    .map(|m| vec![format!("{}*", m)])
                    .unwrap_or_default();

                let config = FlowMonitorConfig {
                    enabled,
                    max_memory_flows,
                    sampling_rate: 1.0, // ç¡®ä¿é‡‡æ ·ç‡ä¸º 100%
                    excluded_models: excluded_models.clone(),
                    ..Default::default()
                };

                let monitor = FlowMonitor::new(config, None);

                // éªŒè¯å¯ç”¨/ç¦ç”¨é…ç½®
                prop_assert_eq!(
                    monitor.is_enabled().await,
                    enabled,
                    "ç›‘æ§å¯ç”¨çŠ¶æ€åº”è¯¥ä¸é…ç½®ä¸€è‡´"
                );

                // æµ‹è¯•æ’é™¤æ¨¡å‹é…ç½®
                if let Some(ref excluded) = excluded_model {
                    let excluded_model_name = format!("{}-test", excluded);
                    let request = LLMRequest {
                        method: "POST".to_string(),
                        path: "/v1/chat/completions".to_string(),
                        model: excluded_model_name,
                        ..Default::default()
                    };
                    let metadata = FlowMetadata::default();

                    let flow_id = monitor.start_flow(request, metadata).await;

                    if enabled {
                        // å¯ç”¨æ—¶ï¼Œæ’é™¤çš„æ¨¡å‹ä¸åº”è¯¥è¢«ç›‘æ§
                        prop_assert!(
                            flow_id.is_none(),
                            "æ’é™¤çš„æ¨¡å‹ä¸åº”è¯¥è¢«ç›‘æ§"
                        );
                    } else {
                        // ç¦ç”¨æ—¶ï¼Œä»»ä½•æ¨¡å‹éƒ½ä¸åº”è¯¥è¢«ç›‘æ§
                        prop_assert!(
                            flow_id.is_none(),
                            "ç¦ç”¨æ—¶ä¸åº”è¯¥ç›‘æ§ä»»ä½•æ¨¡å‹"
                        );
                    }
                }

                // æµ‹è¯•éæ’é™¤æ¨¡å‹
                if enabled {
                    let request = LLMRequest {
                        method: "POST".to_string(),
                        path: "/v1/chat/completions".to_string(),
                        model: "gpt-4".to_string(),
                        ..Default::default()
                    };
                    let metadata = FlowMetadata::default();

                    let flow_id = monitor.start_flow(request, metadata).await;
                    prop_assert!(
                        flow_id.is_some(),
                        "å¯ç”¨æ—¶ï¼Œéæ’é™¤çš„æ¨¡å‹åº”è¯¥è¢«ç›‘æ§"
                    );
                }

                Ok(())
            })?;
        }

        /// **Feature: llm-flow-monitor, Property 12b: ç¼“å­˜å¤§å°é…ç½®ç”Ÿæ•ˆ**
        /// **Validates: Requirements 11.2**
        ///
        /// *å¯¹äºä»»æ„* ç¼“å­˜å¤§å°é…ç½®ï¼Œå†…å­˜å­˜å‚¨çš„æœ€å¤§å¤§å°åº”è¯¥ä¸é…ç½®ä¸€è‡´ã€‚
        #[test]
        fn prop_cache_size_config(
            max_memory_flows in 10usize..100usize,
        ) {
            let rt = Runtime::new().unwrap();
            rt.block_on(async {
                let config = FlowMonitorConfig {
                    enabled: true,
                    max_memory_flows,
                    sampling_rate: 1.0,
                    ..Default::default()
                };

                let monitor = FlowMonitor::new(config, None);

                // éªŒè¯å†…å­˜å­˜å‚¨çš„æœ€å¤§å¤§å°
                let store = monitor.memory_store.read().await;
                prop_assert_eq!(
                    store.max_size(),
                    max_memory_flows,
                    "å†…å­˜å­˜å‚¨çš„æœ€å¤§å¤§å°åº”è¯¥ä¸é…ç½®ä¸€è‡´"
                );

                Ok(())
            })?;
        }
    }
}
